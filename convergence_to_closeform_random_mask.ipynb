{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73737bb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import numpy.linalg as LA\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import pdb\n",
    "from scipy.fft import dct\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f24af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35cf927c",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0a9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambient_dimension = 128\n",
    "noise_std = 0.5\n",
    "avg_num = int(50) # number of experiment average\n",
    "num_sample = 64\n",
    "snr = 4 # signal to noise ratio E(<x,beta>)^2/sigma^2\n",
    "\n",
    "# Data generation model:\n",
    "# 1. 1-sparse vector\n",
    "# true_beta = np.zeros([ambient_dimension, 1])\n",
    "# signal_position = 0\n",
    "# true_beta[signal_position] = 1\n",
    "\n",
    "# 2. random gaussian\n",
    "true_beta = np.random.multivariate_normal([0] * ambient_dimension, np.identity(ambient_dimension)).T\n",
    "true_beta /= LA.norm(true_beta)\n",
    "true_beta = true_beta.reshape(-1, 1)\n",
    "\n",
    "# 3. dense signal with spikes\n",
    "#true_beta = np.random.multivariate_normal([0] * ambient_dimension, np.identity(ambient_dimension)).T\n",
    "#for i in range(20):\n",
    "#    true_beta[i] = 0\n",
    "#spike_strength = 10000\n",
    "#true_beta[0] = np.sqrt(spike_strength) * LA.norm(true_beta)\n",
    "\n",
    "# 2. input data distribution\n",
    "Sigma = np.identity(ambient_dimension)\n",
    "smallest_eig = .2 # choose 1 if you want uniform spectrum\n",
    "decay = smallest_eig ** (1 / ambient_dimension)\n",
    "#decay = 0.95\n",
    "for i in range(ambient_dimension):\n",
    "    Sigma[i, i] = decay ** abs(i)\n",
    "\n",
    "#bi-level spectrum\n",
    "# Sigma = np.identity(ambient_dimension)\n",
    "# for i in range(int(ambient_dimension / 2), ambient_dimension):\n",
    "#     Sigma[i, i] = smallest_eig\n",
    "\n",
    "# random spectrum\n",
    "# Sigma = np.diag(np.random.multivariate_normal([0] * ambient_dimension, np.identity(ambient_dimension)).T)\n",
    "# for i in range(ambient_dimension):\n",
    "#     Sigma[i, i] = abs(Sigma[i, i])\n",
    "\n",
    "# rescale spectrum so that SNR is the same as specified\n",
    "alpha = snr * noise_std ** 2 / (true_beta.T.dot(Sigma).dot(true_beta)[0][0])\n",
    "Sigma *= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af77eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator Function\n",
    "def get_ridge_est(X, y, ridge):\n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    reg = np.identity(d)\n",
    "    S = LA.inv(X.T.dot(X) + n * ridge * reg).dot(X.T) if ridge > 0 else LA.pinv(X.T.dot(X)).dot(X.T)\n",
    "    return S.dot(y)\n",
    "\n",
    "def get_pepper_est(X, y, ridge, p):\n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    reg = np.identity(d)\n",
    "    psi = p / (1 - p)\n",
    "    Cov = X.T.dot(X)\n",
    "    diag = np.diag(np.diag(Cov))\n",
    "    S = LA.inv(Cov + psi / (1 - p) * n * ridge * reg + psi * diag).dot(X.T) if (ridge > 0 or p > 0) else LA.pinv(X.T.dot(X)).dot(X.T)\n",
    "    return S.dot(y)\n",
    "\n",
    "def get_lse_est(X, y):\n",
    "    Cov = X.T.dot(X)\n",
    "    # faster LSE approximation\n",
    "    #est = LA.inv(Cov+1e-10*np.identity(d)).dot(X.T.dot(y))\n",
    "    S = LA.pinv(Cov).dot(X.T)\n",
    "    return S.dot(y)\n",
    "\n",
    "def get_crop_est(X, y, p):\n",
    "    Cov = X.T.dot(X)\n",
    "    diag = np.diag(np.diag(Cov))\n",
    "    Z = (1-p) * Cov + p * diag\n",
    "    S = LA.inv(Z).dot((1 - p) * X.T)\n",
    "    return S.dot(y)\n",
    "\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "def manha(beta_cls, beta):\n",
    "    diff = beta - beta_cls\n",
    "    return np.sqrt(diff.T.dot(Sigma).dot(diff)[0][0])\n",
    "\n",
    "def get_risk(beta):\n",
    "    diff = beta - true_beta\n",
    "    return diff.T.dot(Sigma).dot(diff)[0][0]\n",
    "\n",
    "def solve_aSGD_torch(X1, y1, aug_file, beta_cls, beta_lse, batch_size, aug_size, pass_list):\n",
    "    # output pass_list, risk_list, beta2true_EucDist_list, beta2true_MahaDist_list, beta2lse_EucDist_list, beta2lse_MahaDist_list\n",
    "\n",
    "    aug_type = aug_file['type']\n",
    "    aug_para = aug_file['para']\n",
    "    X = copy.deepcopy(X1)\n",
    "    y = copy.deepcopy(y1)\n",
    "    inputDim = X.shape[1]\n",
    "    outputDim = 1\n",
    "    learningRate =1.2 * 1e-5\n",
    "    pass_lim = int(pass_list[-1])\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = LinearRegression(inputDim, outputDim).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    inputs, labels = torch.from_numpy(X).to(device), torch.from_numpy(y).to(device)\n",
    "    dataset = TensorDataset(inputs, labels)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    #scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "    ret = [[], [], [], [], [], []]\n",
    "    epoch_lim = pass_lim\n",
    "    pass_counter = 0\n",
    "    pass_id = 0\n",
    "    #scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "    for epoch in range(epoch_lim + 1):\n",
    "    # Converting inputs and labels to Variable\n",
    "        for xb, yb in train_loader:\n",
    "\n",
    "            # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "            optimizer.zero_grad()\n",
    "            x1 = xb.expand(aug_size, *xb.size())\n",
    "            if aug_type == 'ridge':\n",
    "                x1 = x1 + torch.normal(0.0, aug_para, size=x1.size(), device=xb.device) if aug_para > 0 else x1\n",
    "            if aug_type == 'crop':\n",
    "                x1 = x1 * (torch.empty(x1.size(), dtype=torch.float32, device=xb.device).uniform_(0, 1) > aug_para) / (1 - aug_para)\n",
    "            if aug_type == 'pepper':\n",
    "                mask = (torch.empty(x1.size(), dtype=torch.float32, device=xb.device).uniform_(0, 1) > aug_para[1])\n",
    "                noise = torch.normal(0.0, aug_para[0], size=x1.size(), device=xb.device) if aug_para[0] > 0 else torch.zeros(size=x1.size())\n",
    "                x1 = x1 * mask + noise * ~mask\n",
    "                x1 /= (1 - aug_para[1])\n",
    "            x1 = x1.float()\n",
    "            y1 = yb.expand(aug_size, *yb.size())\n",
    "            y1 = y1.float()\n",
    "            out = model(x1)\n",
    "            loss = criterion(out, y1)\n",
    "\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if pass_id < len(pass_list) and pass_counter == pass_list[pass_id]:\n",
    "                ret[0].append(epoch)\n",
    "                beta = model.linear.weight.detach().numpy()\n",
    "                ret[1].append(get_risk(beta.reshape(-1, 1)))\n",
    "                ret[2].append(LA.norm(beta.reshape(-1, 1)-beta_cls))\n",
    "                ret[3].append(manha(beta.reshape(-1, 1), beta_cls))\n",
    "                ret[4].append(LA.norm(beta.reshape(-1, 1)-beta_lse))\n",
    "                ret[5].append(manha(beta.reshape(-1, 1), beta_lse))\n",
    "                pass_id += 1\n",
    "\n",
    "            pass_counter+=1\n",
    "        #scheduler.step()\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cc5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set range of parameters of DA\n",
    "# \"crop_finite\": dropout with k fixed patterns, \"crop\": dropout with p dropout rate, \n",
    "# \"ridge\": add gaussian with power sigma s^2, \"proj\": random projection with k dimensional space,\n",
    "\n",
    "ridge_params = np.concatenate((np.zeros(1), np.power(2, np.linspace(-5, 1, num=3))))\n",
    "crop_params = np.concatenate((np.linspace(0, 0.4, num=4), np.linspace(.5, .99, num=0)))\n",
    "pepper_params = {\"ridge\": [0.5, 1] * 2, \"drop_prob\": [0.1, 0.1, 0.3, 0.3]}\n",
    "\n",
    "ridge_params = [1]\n",
    "crop_params = [0.01]\n",
    "pepper_params = [{\"ridge\": 1, \"drop_prob\": crop_params[0]}]\n",
    "\n",
    "batch_aug_list = [(1, 256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbbe9b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [8:47:06<52:04:43, 4360.09s/it]"
     ]
    }
   ],
   "source": [
    "pass_list = range(0, 50001, 50)\n",
    "risk_ridge = np.zeros([avg_num, len(ridge_params), len(batch_aug_list), len(pass_list)])\n",
    "toCLS_ridge = np.zeros([avg_num, len(ridge_params), len(batch_aug_list), len(pass_list)])\n",
    "risk_crop = np.zeros([avg_num, len(crop_params), len(batch_aug_list), len(pass_list)])\n",
    "toCLS_crop = np.zeros([avg_num, len(crop_params), len(batch_aug_list), len(pass_list)])\n",
    "risk_pepper = np.zeros([avg_num, len(pepper_params), len(batch_aug_list), len(pass_list)])\n",
    "toCLS_pepper = np.zeros([avg_num, len(pepper_params), len(batch_aug_list), len(pass_list)])\n",
    "\n",
    "risk_ridge_cls = np.zeros([avg_num, len(ridge_params)])\n",
    "risk_crop_cls = np.zeros([avg_num, len(crop_params)])\n",
    "risk_crop_lse = np.zeros([avg_num, len(crop_params)])\n",
    "risk_pepper_cls = np.zeros([avg_num, len(pepper_params)])\n",
    "risk_lse = np.zeros([avg_num])\n",
    "\n",
    "# Simulate risk\n",
    "np.random.seed(1)\n",
    "start = time.time()\n",
    "X = np.zeros([num_sample, ambient_dimension])\n",
    "y = np.zeros([num_sample, 1])\n",
    "for j in range(num_sample):\n",
    "    X[j, :] = np.random.multivariate_normal([0] * ambient_dimension, Sigma).reshape(-1)\n",
    "    y[j, 0] = np.inner(true_beta.reshape(-1), X[j, :]) + np.random.normal(0, noise_std)\n",
    "for i in tqdm(range(avg_num)):\n",
    "    # LSE\n",
    "    beta_lse = get_lse_est(X, y)\n",
    "    risk_lse[i] = get_risk(beta_lse)\n",
    "    # get loss\n",
    "    # for j in range(len(ridge_params)):\n",
    "    #     for m in range(len(batch_aug_list)):\n",
    "    #         aug_file = {'type': 'ridge', 'para': np.sqrt(ridge_params[j])}\n",
    "    #         batch_size, aug_size = batch_aug_list[m]\n",
    "    #         beta_cls = get_ridge_est(X, y, ridge_params[j])\n",
    "    #         risk_ridge_cls[i, j] = get_risk(beta_cls)\n",
    "    #         traj = solve_aSGD_torch(X, y, aug_file, beta_cls, beta_lse, batch_size, aug_size, pass_list)\n",
    "    #         risk_ridge[i, j, m, :] = traj[1]\n",
    "    #         toCLS_ridge[i, j, m, :] = traj[2]\n",
    "    for j in range(len(crop_params)):\n",
    "        for m in range(len(batch_aug_list)):\n",
    "            aug_file = {'type': 'crop', 'para': crop_params[j]}\n",
    "            batch_size, aug_size = batch_aug_list[m]\n",
    "            beta_cls = get_crop_est(X, y, crop_params[j])\n",
    "            beta_mlse = get_crop_est(X, y, 0.0000001)\n",
    "            risk_crop_cls[i, j] = get_risk(beta_cls)\n",
    "            risk_crop_lse[i, j] = get_risk(beta_mlse)\n",
    "            traj = solve_aSGD_torch(X, y, aug_file, beta_cls, beta_lse, batch_size, aug_size, pass_list)\n",
    "            risk_crop[i, j, m, :] = traj[1]\n",
    "            toCLS_crop[i, j, m, :] = traj[2]\n",
    "    # for j in range(len(pepper_params)):\n",
    "    #     for m in range(len(batch_aug_list)):\n",
    "    #         aug_file = {'type': 'pepper', 'para': (np.sqrt(pepper_params[j]['ridge']), pepper_params[j]['drop_prob'])}\n",
    "    #         batch_size, aug_size = batch_aug_list[m]\n",
    "    #         beta_cls = get_pepper_est(X, y, pepper_params[j]['ridge'], pepper_params[j]['drop_prob'])\n",
    "    #         risk_pepper_cls[i, j] = get_risk(beta_cls)\n",
    "    #         traj = solve_aSGD_torch(X, y, aug_file, beta_cls, beta_lse, batch_size, aug_size, pass_list)\n",
    "    #         risk_pepper[i, j, m, :] = traj[1]\n",
    "    #         toCLS_pepper[i, j, m, :] = traj[2]\n",
    "risk_crop_var = np.std(risk_crop, axis=0)\n",
    "\n",
    "risk_ridge = np.mean(risk_ridge, axis=0)\n",
    "risk_ridge_cls = np.mean(risk_ridge_cls, axis=0)\n",
    "toCLS_ridge = np.mean(toCLS_ridge, axis=0)\n",
    "risk_crop = np.mean(risk_crop, axis=0)\n",
    "risk_crop_cls = np.mean(risk_crop_cls, axis=0)\n",
    "risk_crop_lse = np.mean(risk_crop_lse, axis=0)\n",
    "toCLS_crop = np.mean(toCLS_crop, axis=0)\n",
    "risk_pepper = np.mean(risk_pepper, axis=0)\n",
    "risk_pepper_cls = np.mean(risk_pepper_cls, axis=0)\n",
    "toCLS_pepper = np.mean(toCLS_pepper, axis=0)\n",
    "\n",
    "end = time.time()\n",
    "print('Complete in {} sec'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a67546",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdb0c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "viridis = cm.get_cmap('viridis', 8)\n",
    "linewidth = 2.0\n",
    "tick_size = 25\n",
    "marker = ['x', '.', 'o', 'D', '+', 'P', 'X']\n",
    "markersize = 8\n",
    "\n",
    "plt.figure(figsize=(35, 20))\n",
    "plt.subplot(2,3,1)\n",
    "x_ax = pass_list\n",
    "for i in range(len(ridge_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_ridge[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if ridge_params[i] > 0:\n",
    "        plt.plot(x_ax, [risk_ridge_cls[i]] * len(x_ax), markersize=8,  linewidth=2*linewidth, c=viridis(-100), label= 'closed form')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=20)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Adding Gaussian Noise, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f'), fontsize=20)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "for i in range(len(crop_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_crop[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if crop_params[i] > 0:\n",
    "        plt.plot(x_ax, [risk_crop_cls[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(-100), label='closed form')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=20)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Random Mask, \" + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=20)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "for i in range(len(pepper_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_pepper[i, m], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if pepper_params[i]['ridge']  > 0 or pepper_params[i]['drop_prob'] > 0:\n",
    "        plt.plot(x_ax, [risk_pepper_cls[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(-100), label='closed form')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=20)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Pepper, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f') + ', ' + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=20)\n",
    "\n",
    "\n",
    "ax = plt.subplot(2,3,4)\n",
    "for i in range(len(ridge_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, toCLS_ridge[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "ax.set_ylabel('Estimator Convergence ' + r'$\\|\\hat{\\theta}-\\theta_{cls}\\|_2$', fontsize=20)\n",
    "#ax1.set_ylabel(r'$\\|\\hat{\\theta}-\\theta_{lse}\\|_2$', fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=tick_size)\n",
    "#ax1.tick_params(axis='y', labelsize=30)\n",
    "ax.tick_params(axis='x', labelsize=tick_size)\n",
    "plt.title(f\"Adding Gaussian Noise, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f'), fontsize=20)\n",
    "\n",
    "\n",
    "ax = plt.subplot(2,3,5)\n",
    "for i in range(len(crop_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, toCLS_crop[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize)\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "ax.set_ylabel('Estimator Convergence ' + r'$\\|\\hat{\\theta}-\\theta_{cls}\\|_2$', fontsize=20)\n",
    "#ax1.set_ylabel(r'$\\|\\hat{\\theta}-\\theta_{lse}\\|_2$', fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=tick_size)\n",
    "#ax1.tick_params(axis='y', labelsize=30)\n",
    "ax.tick_params(axis='x', labelsize=tick_size)\n",
    "plt.title(f\"Random Mask, \" + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=20)\n",
    "\n",
    "ax = plt.subplot(2,3,6)\n",
    "for i in range(len(pepper_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, toCLS_pepper[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=20)\n",
    "ax.set_ylabel('Estimator Convergence ' + r'$\\|\\hat{\\theta}-\\theta_{cls}\\|_2$', fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=tick_size)\n",
    "ax.tick_params(axis='x', labelsize=tick_size)\n",
    "#plt.yscale('log')\n",
    "plt.title(f\"Pepper, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f') + ', ' + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=20)\n",
    "\n",
    "#plt.suptitle(f'SNR = {snr: 0.2f}, dimension = {ambient_dimension}, num_sample = {num_sample}',fontsize=30, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998754f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 10))\n",
    "plt.subplot(1,3,1)\n",
    "x_ax = pass_list\n",
    "for i in range(len(ridge_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_ridge[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if ridge_params[i] > 0:\n",
    "        plt.plot(x_ax, [risk_ridge_cls[i]] * len(x_ax), markersize=8,  linewidth=2*linewidth, c=viridis(-100), label= 'aERM solution')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=30)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=30)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Gaussian Noise Injection, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f'), fontsize=30)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "for i in range(len(crop_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_crop[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if crop_params[i] > 0:\n",
    "        plt.plot(x_ax, [risk_crop_cls[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(-100), label='M-LSE')\n",
    "    plt.plot(x_ax, [risk_lse[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(3), label='LSE')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=30)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=30)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Random Mask, \" + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=30)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "for i in range(len(pepper_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        plt.plot(x_ax, risk_pepper[i, m], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), marker=marker[m], markersize=markersize) # Gaussian noise\n",
    "    if pepper_params[i]['ridge']  > 0 or pepper_params[i]['drop_prob'] > 0:\n",
    "        plt.plot(x_ax, [risk_pepper_cls[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(-100), label='aERM solution')\n",
    "plt.legend(loc=\"upper right\", prop={'size': 25})\n",
    "plt.xlabel('Backward Pass', fontsize=30)\n",
    "plt.ylabel('Testing Risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=30)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Pepper, \" + r'$\\sigma=$'+format(round(np.sqrt(pepper_params[0]['ridge']),3), '.2f') + ', ' + r'$p=$'+format(round(pepper_params[0]['drop_prob'],3), '.2f'), fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced5df2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "markersize=20\n",
    "plt.figure(figsize=(15, 10))\n",
    "legendsize = 35\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 5\n",
    "for i in range(len(crop_params)):\n",
    "    for m in range(len(batch_aug_list)):\n",
    "        batch_size, aug_size = batch_aug_list[m]\n",
    "        #ci = 1.96 * risk_crop_var\n",
    "        plt.plot(x_ax, risk_crop[i, m, :], label='(batch, aug) = (' + format(batch_size) + \\\n",
    "                                                      ', ' + format(aug_size) + ')', linewidth=2*linewidth, c=viridis(0.2 * (len(batch_aug_list) - m - 2)), markersize=markersize, ls='--') # Gaussian noise\n",
    "        plt.fill_between(x_ax, risk_crop[i, m, :] - 1.645 * risk_crop_var[i, m, :],  risk_crop[i, m, :] + 1.645 * risk_crop_var[i, m, :], color=viridis(0.2 * (len(batch_aug_list) - m - 2)),alpha=0.3)\n",
    "    if crop_params[i] > 0:\n",
    "        plt.plot(x_ax, [risk_crop_cls[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(-100), label='aERM', linestyle='-', markersize=20)\n",
    "        plt.plot(x_ax, [risk_crop_lse[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(6), label='M-LSE', alpha=0.6)\n",
    "    plt.plot(x_ax, [risk_lse[i]] * len(x_ax),  linewidth=2*linewidth, c=viridis(4), label='LSE')\n",
    "leg = plt.legend(loc=\"upper right\", prop={'size': legendsize})\n",
    "leg.get_frame().set_linewidth(3.0)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "plt.xlabel('Backward pass', fontsize=30)\n",
    "plt.ylabel('Testing risk '+ r'$\\|\\hat{\\theta}-\\theta^*\\|^2_{\\Sigma}$', fontsize=30)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.title(f\"Random mask probability \" + r'$\\beta=$'+format(round(pepper_params[0]['drop_prob'],5), '.2f'), fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71c1f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "risk_crop_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73159ffa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}