{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73737bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-a1d160c5b47b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbernoulli\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import numpy.linalg as LA\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf927c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambientDimension = 100\n",
    "sigma = 0.5 # noise power\n",
    "numAvg = int(1 * 1e+0) # number of average\n",
    "base_train_num = 30\n",
    "\n",
    "featureMean = np.zeros(ambientDimension)\n",
    "\n",
    "# Testing Isotropic data \n",
    "a_test = 1\n",
    "Cov1, Cov2 = np.identity(ambientDimension), np.identity(ambientDimension)\n",
    "decay = .9\n",
    "for i in range(ambientDimension):\n",
    "    Cov1[i, i] = decay ** (i - 1)\n",
    "for i in range(ambientDimension)[::-1]:\n",
    "    Cov2[i, i] = decay ** (i - 1)\n",
    "featureCov = a_test * Cov1 + (1 - a_test) * Cov2\n",
    "betaStar = np.random.multivariate_normal(featureMean, featureCov).reshape(-1,1)\n",
    "betaStar /= LA.norm(betaStar)\n",
    "\n",
    "# training data\n",
    "train_mean = np.zeros(ambientDimension)\n",
    "a_train = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af77eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator Function\n",
    "def getRidgeEst(X, y, yc, ridge):\n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    idm = np.identity(d)\n",
    "    S = LA.pinv(X.T.dot(X) + n * ridge * idm).dot(X.T)\n",
    "    return S.dot(y), S.dot(yc)\n",
    "\n",
    "def getLSEst(X, y):\n",
    "    Cov = X.T.dot(X)\n",
    "    #d = X.shape[1]\n",
    "    # faster LSE approximation\n",
    "    #est = LA.inv(Cov+1e-10*np.identity(d)).dot(X.T.dot(y))\n",
    "    S = LA.pinv(Cov).dot(X.T)\n",
    "    return S.dot(y)\n",
    "\n",
    "def getCropEst(X, y, yc, p):\n",
    "    Cov = X.T.dot(X)\n",
    "    d, n = X.shape[1], X.shape[0]\n",
    "    diag = np.diag(np.diag(Cov))\n",
    "    a = 0\n",
    "    Z = a * Cov + (1 - a) * ((1-p) * Cov + p * diag)\n",
    "    S = LA.pinv(Z).dot((1 - p) * X.T)\n",
    "    return S.dot(y), S.dot(yc) \n",
    "\n",
    "def get_crop_finite_iter(X, n0, n1, p):\n",
    "    X0 = copy.deepcopy(X)\n",
    "    x = X[n1 % n0, :] * bernoulli.rvs(1-p, size=ambientDimension)\n",
    "    X0 = np.concatenate((X0, x.reshape(1, -1)), axis=0)\n",
    "    return X0\n",
    "    \n",
    "def get_crop_finite_data(X, y, n1, p):\n",
    "    n0 = X.shape[0]\n",
    "    X0 = copy.deepcopy(X)\n",
    "    y0 = copy.deepcopy(y)\n",
    "    y_label = []\n",
    "    for i in range(n0):\n",
    "        y_label += [[y0[i, 0], i]]\n",
    "    for i in range(n1):\n",
    "        x = X0[i % n0, :] * bernoulli.rvs(1-p, size=ambientDimension)\n",
    "        y1 = y0[i % n0, :]\n",
    "        y_label += [[y1[0], i % n0]]\n",
    "        X0 = np.concatenate((X0, x.reshape(1, -1)), axis=0)\n",
    "        y0 = np.concatenate((y0, y1.reshape(1, -1)), axis=0)\n",
    "    return X0, y0, y_label\n",
    "\n",
    "def get_gauss_finite_data(X, y, n1, ridge):\n",
    "    n0 = X.shape[0]\n",
    "    X0 = copy.deepcopy(X)\n",
    "    y0 = copy.deepcopy(y)\n",
    "    y_label = []\n",
    "    for i in range(n0):\n",
    "        y_label += [[y0[i, 0], i]]\n",
    "    for i in range(n1):\n",
    "        x = X0[i % n0, :] + ridge * np.random.multivariate_normal(np.zeros(ambientDimension), np.identity(ambientDimension))\n",
    "        y1 = y0[i % n0, :]\n",
    "        y_label += [[y1[0], i % n0]]\n",
    "        X0 = np.concatenate((X0, x.reshape(1, -1)), axis=0)\n",
    "        y0 = np.concatenate((y0, y1.reshape(1, -1)), axis=0)\n",
    "    return X0, y0, y_label\n",
    "    \n",
    "# Uitlity Functions\n",
    "\n",
    "def getMask(k, p):\n",
    "    mean_mask = 0\n",
    "    for i in range(k):\n",
    "        mean_mask += bernoulli.rvs(1-p, size=ambientDimension)\n",
    "    return mean_mask / k\n",
    "\n",
    "# Risk\n",
    "\n",
    "def getRisk(beta, X_test, y_test):\n",
    "    risk = 0\n",
    "    num_test = X_test.shape[0]\n",
    "    for i in range(num_test):\n",
    "        if y_test[i] * (np.inner(X_test[i, :], beta.reshape(-1))) < 0:\n",
    "            risk += 1\n",
    "        elif y_test[i] * (np.inner(X_test[i, :], beta.reshape(-1))) == 0:\n",
    "            risk += 0.5\n",
    "    risk /= num_test\n",
    "    return risk\n",
    "\n",
    "def get_risk(beta):\n",
    "    z = np.inner(beta.reshape(-1), betaStar.reshape(-1)) / math.sqrt(2) / math.sqrt(beta.T.dot(featureCov).dot(beta)[0])\n",
    "    return 0.5 * (1 - math.erf(z))\n",
    "\n",
    "def getExpRisk(numSampling, numIter, paraList, modeDA):\n",
    "    risk = np.zeros([numIter, len(paraList)])\n",
    "    riskLSE = np.zeros(numIter)\n",
    "            \n",
    "    for t in range(numIter):\n",
    "        X = np.zeros([numSampling, ambientDimension])\n",
    "        y = np.zeros([numSampling, 1])\n",
    "        for i in range(numSampling):\n",
    "            z = random.random()\n",
    "            y[i, 0] = -1 if z <= 0.5 else 1\n",
    "            X[i, :] = (betaStar * y[i, 0] + np.random.multivariate_normal(np.zeros(ambientDimension), featureCov).reshape(-1, 1)).reshape(-1)\n",
    "        X0 = X[:base_train_num, :] # base sample\n",
    "        y0 = y[:base_train_num, :]\n",
    "        \n",
    "        # generate test data\n",
    "        #num_test = 100\n",
    "        #y_test = np.zeros(num_test)\n",
    "        #X_test = np.zeros([num_test, ambientDimension])\n",
    "        #for j in range(num_test):\n",
    "        #    z = random.random()\n",
    "        #    y_test[j] = -1 if z <= 0.5 else 1\n",
    "        #    X_test[j, :] = (betaStar * y_test[j] + np.random.multivariate_normal(np.zeros(ambientDimension), featureCov).reshape(-1, 1)).reshape(-1)\n",
    "        \n",
    "        # baseline LSE\n",
    "        beta_est = getLSEst(X, y)\n",
    "        riskLSE[t] = get_risk(beta_est)\n",
    "        \n",
    "        for j in range(len(paraList)):\n",
    "            if numSampling > base_train_num:\n",
    "                n1 = numSampling - base_train_num\n",
    "                if modeDA == \"crop\":\n",
    "                    X1, y1 = get_crop_finite_data(X0, y0, n1, paraList[j])\n",
    "                elif modeDA == \"ridge\":\n",
    "                    X1, y1 = get_gauss_finite_data(X0, y0, n1, paraList[j]) \n",
    "            else:\n",
    "                X1, y1 = X, y\n",
    "           \n",
    "            beta_est = getLSEst(X1, y1)\n",
    "            risk[t, j] = get_risk(beta_est)\n",
    "    return risk.mean(axis=0), riskLSE.mean()\n",
    "\n",
    "def get_exp_risk(numSampling, numIter, para_ridge, para_crop):\n",
    "    risk_ridge = np.zeros([numIter, len(para_ridge)])\n",
    "    risk_crop = np.zeros([numIter, len(para_crop)])\n",
    "    riskLSE = np.zeros(numIter)\n",
    "            \n",
    "    for t in range(numIter):\n",
    "        \n",
    "        # training sample generation\n",
    "        X = np.zeros([numSampling, ambientDimension])\n",
    "        y = np.zeros([numSampling, 1])\n",
    "        for i in range(numSampling):\n",
    "            z = random.random()\n",
    "            y[i, 0] = -1 if z <= 0.5 else 1\n",
    "            X[i, :] = (betaStar * y[i, 0] + np.random.multivariate_normal(np.zeros(ambientDimension), featureCov).reshape(-1, 1)).reshape(-1)\n",
    "        X0 = X[:base_train_num, :] # base sample\n",
    "        y0 = y[:base_train_num, :]\n",
    "\n",
    "        # baseline LSE\n",
    "        beta_est = getLSEst(X, y)\n",
    "        riskLSE[t] = get_risk(beta_est)\n",
    "        \n",
    "        for j in range(len(para_ridge)):\n",
    "            n1 = numSampling - base_train_num\n",
    "            X1, y1, y1_label = get_gauss_finite_data(X0, y0, n1, para_ridge[j])\n",
    "            beta_est = getLSEst(X1, y1)\n",
    "            risk_ridge[t, j] = get_risk(beta_est)\n",
    "            \n",
    "        for j in range(len(para_crop)):\n",
    "            n1 = numSampling - base_train_num\n",
    "            X2, y2, y2_label = get_crop_finite_data(X0, y0, n1, para_crop[j])\n",
    "           \n",
    "            beta_est = getLSEst(X2, y2)\n",
    "            risk_crop[t, j] = get_risk(beta_est)\n",
    "    return risk_ridge.mean(axis=0), risk_crop.mean(axis=0), riskLSE.mean(), X0, y0, X1, y1_label, X2, y2_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of augmentation:\n",
    "\n",
    "# set range of parameters of DA\n",
    "# \"crop_finite\": dropout with k fixed patterns, \"crop\": dropout with p dropout rate, \n",
    "# \"ridge\": add gaussian with power sigma s^2, \"proj\": random projection with k dimensional space,\n",
    "# \"mixup\": mix-up with beta distribution parameter b\n",
    "ridge_params = np.power(2, np.linspace(-10, 10, num=10))\n",
    "ridge_params = [1]\n",
    "crop_params = np.concatenate((np.linspace(0, 0.4, num=4), np.linspace(.5, 1, num=5)))\n",
    "crop_params = [0.4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = range(5, 4 * ambientDimension, 20)\n",
    "risk_ridge_List = list()\n",
    "risk_crop_List = list()\n",
    "riskLseList = list()\n",
    "\n",
    "# Simulate risk\n",
    "np.random.seed(1)\n",
    "count = 0\n",
    "start = time.time()\n",
    "for i in tqdm(sample):\n",
    "    risk_ridge, risk_crop, risk_lse, X0, y0, X1, y1_label, X2, y2_label = get_exp_risk(i, numAvg, ridge_params, crop_params)\n",
    "    risk_ridge_List.append(risk_ridge)\n",
    "    risk_crop_List.append(risk_crop)\n",
    "    riskLseList.append(risk_lse)\n",
    "    count += 1\n",
    "    # print('Complete {} %'.format(round(count*100/len(sample), 1)))\n",
    "end = time.time()\n",
    "print('Complete in {} sec'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aac7e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "risk_ridge_table = np.zeros([len(sample),len(ridge_params)])\n",
    "for i in range(len(sample)):\n",
    "    for j in range(len(ridge_params)):\n",
    "        risk_ridge_table[i,j] = risk_ridge_List[i][j]\n",
    "        \n",
    "risk_crop_table = np.zeros([len(sample),len(crop_params)])\n",
    "for i in range(len(sample)):\n",
    "    for j in range(len(crop_params)):\n",
    "        risk_crop_table[i,j] = risk_crop_List[i][j]\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sample, riskLseList, label=\"LSE\", color='black', marker='o', markersize=10, linewidth=4.0) \n",
    "for i in range(0, len(ridge_params)):\n",
    "    plt.plot(sample, risk_ridge_table[:,i], label=r'$\\sigma=$'+str(round(np.sqrt(ridge_params[i]),3)), linewidth=4.0) # Gaussian noise\n",
    "    plt.yscale(\"log\")   \n",
    "plt.axvline(x=base_train_num, label='virtual sample threshold = ' + str(base_train_num), c='red', ls='--', linewidth=4.0)\n",
    "#plt.legend(loc=\"upper right\", prop={'size': 15})\n",
    "plt.xlabel('Sample Number', fontsize=20)\n",
    "plt.ylabel('Testing Error', fontsize=20)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.title(\"Adding Gaussian Noise\", fontsize=50)\n",
    "#plt.ylim(1 * 1e-2,1e0)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sample, riskLseList, label=\"LSE\", color='black', marker='o', markersize=10, linewidth=4.0) \n",
    "for i in range(0, len(crop_params)):\n",
    "    plt.plot(sample, risk_crop_table[:,i],label=r'$p=$'+str(round(crop_params[i],3)), linewidth=4.0) # Random crop\n",
    "    plt.yscale(\"log\")   \n",
    "plt.axvline(x=base_train_num, label='virtual sample threshold = ' + str(base_train_num), c='red', ls='--', linewidth=4.0)\n",
    "#plt.legend(loc=\"lower left\", prop={'size': 15})\n",
    "plt.xlabel('Sample Number', fontsize=20)\n",
    "plt.ylabel('Testing Error', fontsize=20)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.title(\"Random Crop\", fontsize=50)\n",
    "#plt.ylim(1 * 1e-2,1e0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sample, riskLseList, label=\"LSE\", color='black', marker='o', markersize=10, linewidth=4.0)   \n",
    "plt.axvline(x=base_train_num, label='virtual sample threshold = ' + str(base_train_num), c='red', ls='--', linewidth=4.0)\n",
    "#plt.legend(loc=\"upper right\", prop={'size': 15})\n",
    "plt.xlabel('Number of Training Samples', fontsize=30)\n",
    "plt.ylabel('Testing Error', fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.title(\"Classification Experiment\", fontsize=50)\n",
    "#plt.ylim(1 * 1e-2,)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer.add_embedding(X0, metadata=y0, tag='original')\n",
    "writer.add_embedding(X1, metadata=y1_label, tag='add_gaussian', metadata_header=['class', 'id'])\n",
    "writer.add_embedding(X2, metadata=y2_label, tag='random_crop', metadata_header=['class', 'id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=runs (copy and paste this line to the terminal and click enter to open the tensorboard)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}